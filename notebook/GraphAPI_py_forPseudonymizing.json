{
	"name": "GraphAPI_py_forPseudonymizing",
	"properties": {
		"folder": {
			"name": "Archive"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": {
				"version": "0.1"
			},
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			}
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"# This is basically taking what Gene had from MS_Insights, and using it to try and find out how to easily pseudonymize the data from stage2np\r\n",
					"\r\n",
					"class GraphAPI(BaseOEAModule):\r\n",
					"    \"\"\"\r\n",
					"    Provides data processing methods for Graph API data.\r\n",
					"    Data is expected to be received via AAD into stage1np/GraphAPI\r\n",
					"    The structure of the folders in stage1np will then be something like:\r\n",
					"        -> stage1np/GraphAPI/users\r\n",
					"            -> stage1np/GraphAPI/users/users_2021-06-02.json\r\n",
					"        -> stage1np/GraphAPI/m365_app_user_detail/\r\n",
					"            -> stage1np/GraphAPI/m365_app_user_detail/m365_app_user_detail_2021-06-02T06-05-11.json\r\n",
					"            etc\r\n",
					"\r\n",
					"    In stage2, everything is written to stage2np/GraphAPI and stage2p/GraphAPI\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    def __init__(self, oea, source_folder='GraphAPI'):\r\n",
					"        BaseOEAModule.__init__(self, oea, source_folder)\r\n",
					"\r\n",
					"        self.stage1np_GraphAPI = self.stage1np + '/GraphAPI'\r\n",
					"\r\n",
					"        self.schemas['users'] = [['surname', 'string', 'mask'],\r\n",
					"                        ['giveName', 'string', 'mask'],\r\n",
					"                        ['userPrincipalName', 'string', 'hash'],\r\n",
					"                        ['id', 'string', 'no-op']]\r\n",
					"        \r\n",
					"        self.schemas['m365_app_user_detail'] = [['reportRefreshDate', 'string', 'no-op'],\r\n",
					"                        ['userPrincipalName', 'string', 'hash-no-lookup'],\r\n",
					"                        ['lastActivityDate', 'string', 'no-op'],\r\n",
					"                        ['reportPeriod', 'integer', 'no-op'],\r\n",
					"                        ['excel', 'boolean', 'no-op'],\r\n",
					"                        ['excelWeb', 'boolean', 'no-op'],\r\n",
					"                        ['outlook', 'boolean', 'no-op'],\r\n",
					"                        ['outlookWeb', 'boolean', 'no-op'],\r\n",
					"                        ['powerPoint', 'boolean', 'no-op'],\r\n",
					"                        ['powerPointWeb', 'boolean', 'no-op'],\r\n",
					"                        ['teams', 'boolean', 'no-op'],\r\n",
					"                        ['teamsWeb', 'boolean', 'no-op'],\r\n",
					"                        ['word', 'boolean', 'no-op'],\r\n",
					"                        ['wordWeb', 'boolean', 'no-op']]\r\n",
					"\r\n",
					"        self.schemas['teams_activity_user_details'] = [['reportRefreshDate', 'string', 'no-op'],\r\n",
					"                        ['reportPeriod', 'integer', 'no-op'],\r\n",
					"                        ['userPrincipalName', 'string', 'hash-no-lookup'],\r\n",
					"                        ['privateChatMessageCount', 'integer', 'no-op'],\r\n",
					"                        ['teamChatMessageCount', 'integer', 'no-op'],\r\n",
					"                        ['meetingsAttendedCount', 'integer', 'no-op'],\r\n",
					"                        ['meetingCount', 'integer', 'no-op']\r\n",
					"                        ['audioDuration', 'duration', 'no-op']]\r\n",
					"    \r\n",
					"    def process_users(self):\r\n",
					"        \"\"\" Processes users data from stage1np into stage2 using structured streaming. \"\"\"\r\n",
					"        logger.info(\"Processing GraphAPI users data from: \" + self.stage1np_GraphAPI)\r\n",
					"\r\n",
					"        spark_schema = self.oea.to_spark_schema(self.schemas['users'])\r\n",
					"        df = spark.readStream.json(self.stage1np_GraphAPI + '/*.json', header='false', schema=spark_schema)\r\n",
					"        #df = df.withColumn('year', F.year(F.col('StartTime'))).withColumn('month', F.month(F.col('StartTime')))\r\n",
					"\r\n",
					"        df_pseudo, df_lookup = self.oea.pseudonymize(df, self.schemas['users'])\r\n",
					"\r\n",
					"        query = df_pseudo.writeStream.format(\"delta\").outputMode(\"append\").trigger(once=True).option(\"checkpointLocation\", self.stage1np_activity + '/_checkpoints').partitionBy('year', 'month')\r\n",
					"        query = query.start(self.stage2p + '/users')\r\n",
					"        query.awaitTermination()   # block until query is terminated, with stop() or with error; A StreamingQueryException will be thrown if an exception occurs.\r\n",
					"        logger.info(query.lastProgress)"
				],
				"attachments": null,
				"execution_count": null
			}
		]
	}
}